{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter: An Analysis in Linguistic Diversity\n",
    "\n",
    "In the past century, human mobility is at its greatest since our dawn. This mobility begets diverse hotspots across the landscape. However, some places are more diverse than others. A copule of questions should come to mind. What is meant when we call a place diverse? Why type of diversity? In this case, we are talking about the topography of langauges for particular cities across the United States, but we could be measuring ethnic or socioeconomic diversity. How do we measure diversity? These are just a few of the questions that we will be exploring as we begin to formalize our understanding of big data manipulation.\n",
    "\n",
    "----\n",
    "\n",
    "### Linguistic Diversity and Twitter's role\n",
    "\n",
    "What is linguistic diversity? For our purposes, linguistic diversity is a some sort of measure that accounts for both the number of languages spoken in a particular area as well as the number of speakers per language. This is where Twitter comes in. Collecting language data on a region, in this case cities, is particularly difficult, and if you ware wanting to find an open source dataset with such linguistic information, you would be hard pressed to find one that counts up past five distinct languages. Twitter, however, provides the language spoken in the Tweet as an attribute accessible through their API. It also allows a user to collect on tweets within a specified region by specifying a geographic radius around a city. This gives us the unique ability to analyze the linguistic landscape of a given region. This, of course, can be compared between locations or evaluated across time splits in the data. \n",
    "\n",
    "It is also important to note that this may not be representative of any given physical location. In fact, it almost certainly overweights English's speakers compared to others. A large proportion of Twitter is written in English, more so than there are native English speakers. Yet, this doesn't mean that there isn't any connection to the physical landscape. In fact, all things being equal, the expectation would that more diverse Twitter cities are also more diverse physical cites and vice versa. However, we won't be making such assumptions throughout these notebooks. To do so would take some sort of validation which is outside of the purview of these lessons.\n",
    "\n",
    "----\n",
    "\n",
    "### The Data\n",
    "\n",
    "The Twitter data are stored in a Postgres database and contains several tables. The primary table that we will be working with is the `tweet` table, however, there are also a `hashtag`, `mention`, `url` and `job` table. We will come back to these, but for the time being, let's go over the `tweet` table and its attributes.\n",
    "\n",
    "\n",
    "attribute     | description\n",
    "--------------|------------\n",
    "`tweet_id_str`| tweet's identifier\n",
    "`job_id`      | job identifier (pertaining to geographic location)\n",
    "`created_at`  | when the tweet was written\n",
    "`text`        | the text of the tweet\n",
    "`from_user`   | user id who created the tweet\n",
    "`from_user_name`| username of tweet creator\n",
    "`from_user_created_at`| the date the user was created\n",
    "`from_user_followers`| number of followers the user has\n",
    "`from_user_following`| number of people the user is following\n",
    "`from_user_favorites`| sum of likes of user's tweets\n",
    "`to_user`     | the id of the person the user tweeted at\n",
    "`to_user_name`| the user name of the person tweeted at\n",
    "`location_geo`| the coordinates of where the tweet was sent out\n",
    "`iso_language`| the language of the tweet\n",
    "\n",
    "We can also query for the column names of the table and their data type..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tweet_id_str', 'character varying', 'NO'),\n",
       " ('job_id', 'integer', 'NO'),\n",
       " ('created_at', 'timestamp without time zone', 'NO'),\n",
       " ('text', 'text', 'NO'),\n",
       " ('from_user', 'character varying', 'NO'),\n",
       " ('from_user_id_str', 'character varying', 'NO'),\n",
       " ('from_user_name', 'character varying', 'NO'),\n",
       " ('from_user_fullname', 'text', 'NO'),\n",
       " ('from_user_created_at', 'timestamp without time zone', 'NO'),\n",
       " ('from_user_followers', 'integer', 'NO'),\n",
       " ('from_user_following', 'integer', 'NO'),\n",
       " ('from_user_favorites', 'integer', 'NO'),\n",
       " ('from_user_tweets', 'integer', 'NO'),\n",
       " ('from_user_timezone', 'character varying', 'YES'),\n",
       " ('to_user', 'character varying', 'YES'),\n",
       " ('to_user_id_str', 'character varying', 'YES'),\n",
       " ('to_user_name', 'character varying', 'YES'),\n",
       " ('source', 'text', 'YES'),\n",
       " ('location_geo', 'text', 'YES'),\n",
       " ('location_geo_0', 'numeric', 'YES'),\n",
       " ('location_geo_1', 'numeric', 'YES'),\n",
       " ('iso_language', 'character varying', 'NO'),\n",
       " ('analysis_state', 'integer', 'YES')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define our query\n",
    "statement = \"\"\"SELECT column_name, data_type, is_nullable\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_name = 'tweet';\"\"\"\n",
    "\n",
    "try:\n",
    "    connect_str = \"dbname='twitter' user='dsa_ro_user' host='dbase.dsa.missouri.edu'password='readonly'\"\n",
    "    # use our connection values to establish a connection\n",
    "    conn = psycopg2.connect(connect_str)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # execute the statement from above\n",
    "    cursor.execute(statement)\n",
    "    # fetch all of the rows associated with the query\n",
    "    cols = cursor.fetchall()\n",
    "except Exception as e:\n",
    "    print(\"Uh oh, can't connect. Invalid dbname, user or password?\")\n",
    "    print(e)\n",
    "    \n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we have a good idea about type of information the `tweet` table contains so let's return to the other tables in the database. We mentioned these above, but if you were just curious about what tables existed in the database, you could query Postgress for it like so..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tweet',), ('url',), ('mention',), ('hashtag',), ('job',)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"\"\"SELECT table_name \n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'twitter'\"\"\"\n",
    "\n",
    "\n",
    "try:\n",
    "    connect_str = \"dbname='twitter' user='dsa_ro_user' host='dbase.dsa.missouri.edu'password='readonly'\"\n",
    "    # use our connection values to establish a connection\n",
    "    conn = psycopg2.connect(connect_str)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(statement)\n",
    "    \n",
    "    tables = cursor.fetchall()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Uh oh, can't connect. Invalid dbname, user or password?\")\n",
    "    print(e)\n",
    "    \n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <span style=\"background-color: #FFFF00\">YOUR TURN</span>\n",
    "\n",
    "Above we ran a bit of code to return the column names of the `tweet` table. Pick one of the tables above (not `tweet`) and check out their columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hashtag_id', 'bigint', 'NO'),\n",
       " ('tweet_id', 'character varying', 'NO'),\n",
       " ('text', 'character varying', 'NO'),\n",
       " ('index_start', 'smallint', 'NO'),\n",
       " ('index_end', 'smallint', 'NO'),\n",
       " ('job_id', 'integer', 'NO'),\n",
       " ('analysis_state', 'integer', 'YES')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put your code here\n",
    "# ------------------\n",
    "statement = \"\"\"SELECT column_name, data_type, is_nullable\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_name = 'hashtag';\"\"\"\n",
    "\n",
    "try:\n",
    "    connect_str = \"dbname='twitter' user='dsa_ro_user' host='dbase.dsa.missouri.edu'password='readonly'\"\n",
    "    # use our connection values to establish a connection\n",
    "    conn = psycopg2.connect(connect_str)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # execute the statement from above\n",
    "    cursor.execute(statement)\n",
    "    # fetch all of the rows associated with the query\n",
    "    cols = cursor.fetchall()\n",
    "except Exception as e:\n",
    "    print(\"Uh oh, can't connect. Invalid dbname, user or password?\")\n",
    "    print(e)\n",
    "    \n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start looking at some of the data now. Most of our analysis revolves around the `tweet` table, so we will pick up from there. We can look at some of the data in the `tweet` table. The first 10 rows should suffice..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('852188225141702658',\n",
       "  284,\n",
       "  datetime.datetime(2017, 4, 12, 15, 54, 40),\n",
       "  'RT @true_pundit: WATCH: Dem Congressman Floats Insane Conspiracy Theory On Live TV, Offers No Evidence #TruePundit https://t.co/W4lqS9Fq6f',\n",
       "  '179987990',\n",
       "  '179987990',\n",
       "  'fjisback',\n",
       "  'Julie G',\n",
       "  datetime.datetime(2010, 8, 18, 15, 36, 39),\n",
       "  168,\n",
       "  155,\n",
       "  34867,\n",
       "  9907,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'en',\n",
       "  0),\n",
       " ('852188225145798657',\n",
       "  290,\n",
       "  datetime.datetime(2017, 4, 12, 15, 54, 40),\n",
       "  '@J_Nova_Kane As long as you have sirracha',\n",
       "  '315966784',\n",
       "  '315966784',\n",
       "  'Shoes_n_Natural',\n",
       "  'AfroditE',\n",
       "  datetime.datetime(2011, 6, 12, 18, 47, 27),\n",
       "  572,\n",
       "  375,\n",
       "  11211,\n",
       "  115584,\n",
       "  'Quito',\n",
       "  '169741804',\n",
       "  '169741804',\n",
       "  'J_Nova_Kane',\n",
       "  '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'en',\n",
       "  0),\n",
       " ('852188225233985536',\n",
       "  273,\n",
       "  datetime.datetime(2017, 4, 12, 15, 54, 40),\n",
       "  \"I'm all for the prospect but am afraid of altering the skyline bc I really like the way it looks now https://t.co/Z9k4oIh4Je\",\n",
       "  '762789480285757440',\n",
       "  '762789480285757440',\n",
       "  'egg_mom2',\n",
       "  'eggmom',\n",
       "  datetime.datetime(2016, 8, 8, 23, 15, 59),\n",
       "  33,\n",
       "  30,\n",
       "  1206,\n",
       "  881,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'en',\n",
       "  0),\n",
       " ('852188225263292421',\n",
       "  275,\n",
       "  datetime.datetime(2017, 4, 12, 15, 54, 40),\n",
       "  'RT @fight4theyouth: Joy is the ultimate rebellion. Happiness is the fastest track to success. Bliss is the best achievement. --@chaninicholâ\\x80¦',\n",
       "  '26175426',\n",
       "  '26175426',\n",
       "  'flowerwheel76',\n",
       "  'Amy Blumenreder',\n",
       "  datetime.datetime(2009, 3, 24, 4, 12, 41),\n",
       "  1286,\n",
       "  2416,\n",
       "  106969,\n",
       "  57457,\n",
       "  'Eastern Time (US & Canada)',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'en',\n",
       "  0),\n",
       " ('852188225422503937',\n",
       "  258,\n",
       "  datetime.datetime(2017, 4, 12, 15, 54, 40),\n",
       "  '@tamarapalooza YEP',\n",
       "  '423986080',\n",
       "  '423986080',\n",
       "  '__blve',\n",
       "  'hali',\n",
       "  datetime.datetime(2011, 11, 29, 5, 22),\n",
       "  381,\n",
       "  352,\n",
       "  39078,\n",
       "  18817,\n",
       "  'Pacific Time (US & Canada)',\n",
       "  '3317200850',\n",
       "  '3317200850',\n",
       "  'tamarapalooza',\n",
       "  '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'und',\n",
       "  0),\n",
       " ('852188225422667776',\n",
       "  284,\n",
       "  datetime.datetime(2017, 4, 12, 15, 54, 40),\n",
       "  '@FueledbyLOLZ happy anniversary!',\n",
       "  '2576924275',\n",
       "  '2576924275',\n",
       "  'HappyRunningCo',\n",
       "  'HappyRunningCo',\n",
       "  datetime.datetime(2014, 6, 19, 13, 49, 4),\n",
       "  693,\n",
       "  485,\n",
       "  12077,\n",
       "  5043,\n",
       "  None,\n",
       "  '216194230',\n",
       "  '216194230',\n",
       "  'FueledbyLOLZ',\n",
       "  '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'en',\n",
       "  0),\n",
       " ('852188225443471360',\n",
       "  269,\n",
       "  datetime.datetime(2017, 4, 12, 15, 54, 40),\n",
       "  'RT @JasonKander: We have to cut public transit funding for working people so POTUS, whose wife and son live in NYC, can fly to Florida by hâ\\x80¦',\n",
       "  '1605994344',\n",
       "  '1605994344',\n",
       "  'LasEkristen',\n",
       "  'Elizabeth Kristen',\n",
       "  datetime.datetime(2013, 7, 19, 14, 12, 36),\n",
       "  1334,\n",
       "  4299,\n",
       "  67,\n",
       "  18999,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'en',\n",
       "  0),\n",
       " ('852188225447890945',\n",
       "  273,\n",
       "  datetime.datetime(2017, 4, 12, 15, 54, 40),\n",
       "  'RT @johnchartman: Not bad Garcia',\n",
       "  '2440571473',\n",
       "  '2440571473',\n",
       "  'Korab_VII',\n",
       "  'Korrigan',\n",
       "  datetime.datetime(2014, 4, 12, 20, 23, 9),\n",
       "  587,\n",
       "  639,\n",
       "  3762,\n",
       "  726,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'en',\n",
       "  0),\n",
       " ('852188225485643780',\n",
       "  275,\n",
       "  datetime.datetime(2017, 4, 12, 15, 54, 40),\n",
       "  '.@PrimeraTech Introduces LX1000 Color Label Printer https://t.co/Wv4nMjMaZP https://t.co/eLZYgYOSBA',\n",
       "  '32906967',\n",
       "  '32906967',\n",
       "  'BevNET',\n",
       "  'BevNET.com',\n",
       "  datetime.datetime(2009, 4, 18, 15, 4, 24),\n",
       "  14266,\n",
       "  1597,\n",
       "  983,\n",
       "  21073,\n",
       "  'Quito',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '<a href=\"http://www.bevnet.com\" rel=\"nofollow\">BevNET</a>',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'es',\n",
       "  0),\n",
       " ('852188225527570433',\n",
       "  273,\n",
       "  datetime.datetime(2017, 4, 12, 15, 54, 40),\n",
       "  'RT @nikkiorion: G://www.smarturl.it/ye',\n",
       "  '712899113113763840',\n",
       "  '712899113113763840',\n",
       "  'lydiamay_2',\n",
       "  'lydia',\n",
       "  datetime.datetime(2016, 3, 24, 7, 9, 28),\n",
       "  68,\n",
       "  321,\n",
       "  6785,\n",
       "  176,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  'en',\n",
       "  0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"\"\"SELECT * \n",
    "FROM twitter.tweet\n",
    "LIMIT 10;\"\"\"\n",
    "\n",
    "try:\n",
    "    connect_str = \"dbname='twitter' user='dsa_ro_user' host='dbase.dsa.missouri.edu'password='readonly'\"\n",
    "    # use our connection values to establish a connection\n",
    "    conn = psycopg2.connect(connect_str)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # execute the statement from above\n",
    "    cursor.execute(statement)\n",
    "    # fetch all of the rows associated with the query\n",
    "    rows = cursor.fetchall()\n",
    "except Exception as e:\n",
    "    print(\"Uh oh, can't connect. Invalid dbname, user or password?\")\n",
    "    print(e)\n",
    "    \n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is kind of a messy way to view the data. Right now we have an object called `rows`, which stores each row in a tuple and all of the tuples are stored in a single list. How about we change this into a more readable format..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statement = \"\"\"SELECT * \n",
    "FROM twitter.tweet\n",
    "LIMIT 10;\"\"\"\n",
    "\n",
    "try:\n",
    "    connect_str = \"dbname='twitter' user='dsa_ro_user' host='dbase.dsa.missouri.edu'password='readonly'\"\n",
    "    # use our connection values to establish a connection\n",
    "    conn = psycopg2.connect(connect_str)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(statement)\n",
    "    \n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "    rows = cursor.fetchall()\n",
    "except Exception as e:\n",
    "    print(\"Uh oh, can't connect. Invalid dbname, user or password?\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily turn this into a dictionary object, which can subsequently be turned into a `pandas DataFrame` object. For this dictionary, the field name (column name) will be the key and the values will be a list of corresponding values in the `rows` object. \n",
    "\n",
    "For example, `rows[<x>][0]` are all values of `tweet_id_str`. Conveniently, `column_names[0]` is `tweet_id_str`. Then all we have to do is create an empty dictionary and begin to fill it with the the contents of `column_names` and `rows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_dict = {}\n",
    "for i in list(range(len(column_names))):\n",
    "     tweet_dict['{}'.format(column_names[i])] = [x[i] for x in rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here? Well, we can assume that the number or values per row should equal the number of column names. Therefore, we iterate through a list ranging from to the length of the `column_names` object and create a key from each column name item (`k['{}'.format(column_names[i])]`). The values are the corresponding value index in the `rows` object. We use the single line list constructor to build a list of values for each key. For a multiline `for` loop that does the same thing, it would look like:\n",
    "\n",
    "```python\n",
    "list_o_lists = [] # create an empty list to store lists of values\n",
    "\n",
    "for i in list(range(len(column_names))):\n",
    "    vals = [] # create empty list to store the values\n",
    "    for x in rows:\n",
    "        vals.append(x[i])\n",
    "    list_o_lists.append(vals)  \n",
    "```\n",
    "\n",
    "...and then turning this dict into a data frame is simple. Just run `pandas`' `DataFrame` method over the dictionary object you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis_state</th>\n",
       "      <th>created_at</th>\n",
       "      <th>from_user</th>\n",
       "      <th>from_user_created_at</th>\n",
       "      <th>from_user_favorites</th>\n",
       "      <th>from_user_followers</th>\n",
       "      <th>from_user_following</th>\n",
       "      <th>from_user_fullname</th>\n",
       "      <th>from_user_id_str</th>\n",
       "      <th>from_user_name</th>\n",
       "      <th>...</th>\n",
       "      <th>job_id</th>\n",
       "      <th>location_geo</th>\n",
       "      <th>location_geo_0</th>\n",
       "      <th>location_geo_1</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>to_user</th>\n",
       "      <th>to_user_id_str</th>\n",
       "      <th>to_user_name</th>\n",
       "      <th>tweet_id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-12 17:57:18</td>\n",
       "      <td>293690109</td>\n",
       "      <td>2011-05-05 20:04:11</td>\n",
       "      <td>180</td>\n",
       "      <td>570</td>\n",
       "      <td>711</td>\n",
       "      <td>âï¸</td>\n",
       "      <td>293690109</td>\n",
       "      <td>_Butter21</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @BleacherReport: MLB commish Rob Manfred wa...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>852219087375781889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-12 17:57:18</td>\n",
       "      <td>4859763987</td>\n",
       "      <td>2016-01-29 10:24:41</td>\n",
       "      <td>129</td>\n",
       "      <td>54</td>\n",
       "      <td>331</td>\n",
       "      <td>Reinardo jose silva</td>\n",
       "      <td>4859763987</td>\n",
       "      <td>JoseVerde28</td>\n",
       "      <td>...</td>\n",
       "      <td>223</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href=\"http://blackberry.com/twitter\" rel=\"n...</td>\n",
       "      <td>RT @WarOfParlay: Ayer Lamentablemente fue un d...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>852219087405150209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-12 17:57:18</td>\n",
       "      <td>3537421936</td>\n",
       "      <td>2015-09-03 20:10:35</td>\n",
       "      <td>1724</td>\n",
       "      <td>330</td>\n",
       "      <td>268</td>\n",
       "      <td>Karen</td>\n",
       "      <td>3537421936</td>\n",
       "      <td>karen_marin02</td>\n",
       "      <td>...</td>\n",
       "      <td>236</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Si no te importa lo que piense la gente, ya di...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>852219087442915330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-12 17:57:18</td>\n",
       "      <td>3056458174</td>\n",
       "      <td>2015-02-23 16:59:19</td>\n",
       "      <td>50357</td>\n",
       "      <td>6117</td>\n",
       "      <td>5763</td>\n",
       "      <td>PROMO GANG C.E.O.</td>\n",
       "      <td>3056458174</td>\n",
       "      <td>ceep757</td>\n",
       "      <td>...</td>\n",
       "      <td>284</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>RT @TUOWLS_WBB: Our Big 5 award winners... hig...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>852219087530991624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-12 17:57:18</td>\n",
       "      <td>849320016315023362</td>\n",
       "      <td>2017-04-04 17:57:26</td>\n",
       "      <td>1067</td>\n",
       "      <td>179</td>\n",
       "      <td>454</td>\n",
       "      <td>Bob Abooey</td>\n",
       "      <td>849320016315023362</td>\n",
       "      <td>BobAbooey8</td>\n",
       "      <td>...</td>\n",
       "      <td>275</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>Watch Shia LaBeouf Text People From A Remote C...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>852219087631650816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-12 17:57:18</td>\n",
       "      <td>43871279</td>\n",
       "      <td>2009-06-01 11:50:18</td>\n",
       "      <td>71484</td>\n",
       "      <td>2588</td>\n",
       "      <td>2298</td>\n",
       "      <td>absentminded</td>\n",
       "      <td>43871279</td>\n",
       "      <td>mlccm</td>\n",
       "      <td>...</td>\n",
       "      <td>290</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @nattylumpo88: Ok. Alright. We get it. You ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>852219087845511173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-12 17:57:18</td>\n",
       "      <td>30308791</td>\n",
       "      <td>2009-04-10 20:46:41</td>\n",
       "      <td>13742</td>\n",
       "      <td>473</td>\n",
       "      <td>596</td>\n",
       "      <td>Shaker Pepper</td>\n",
       "      <td>30308791</td>\n",
       "      <td>shakepepper</td>\n",
       "      <td>...</td>\n",
       "      <td>269</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>RT @cdotharrison: I saw Charlie Murphy at the ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>852219087954493440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-12 17:57:18</td>\n",
       "      <td>46049431</td>\n",
       "      <td>2009-06-10 05:56:50</td>\n",
       "      <td>283</td>\n",
       "      <td>6197</td>\n",
       "      <td>1693</td>\n",
       "      <td>Plushbeds.com</td>\n",
       "      <td>46049431</td>\n",
       "      <td>plushbeds</td>\n",
       "      <td>...</td>\n",
       "      <td>284</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href=\"http://www.audiense.com\" rel=\"nofollo...</td>\n",
       "      <td>@HBQ_1 We've got a question for you: about how...</td>\n",
       "      <td>17570566</td>\n",
       "      <td>17570566</td>\n",
       "      <td>HBQ_1</td>\n",
       "      <td>852219087967145984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-12 17:57:18</td>\n",
       "      <td>3431548829</td>\n",
       "      <td>2015-08-19 14:21:23</td>\n",
       "      <td>592</td>\n",
       "      <td>25</td>\n",
       "      <td>106</td>\n",
       "      <td>RRussell</td>\n",
       "      <td>3431548829</td>\n",
       "      <td>RRussell74351</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href=\"http://www.twitter.com\" rel=\"nofollow...</td>\n",
       "      <td>RT @saladinahmed: it's not 'sharia' if you're ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>852219088059412482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-12 17:57:18</td>\n",
       "      <td>356713597</td>\n",
       "      <td>2011-08-17 07:44:59</td>\n",
       "      <td>6372</td>\n",
       "      <td>362</td>\n",
       "      <td>714</td>\n",
       "      <td>Leah</td>\n",
       "      <td>356713597</td>\n",
       "      <td>brLeaHkaway</td>\n",
       "      <td>...</td>\n",
       "      <td>275</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @celtics: Get ready for the playoffs with t...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>852219088113999882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis_state          created_at           from_user  \\\n",
       "0               0 2017-04-12 17:57:18           293690109   \n",
       "1               0 2017-04-12 17:57:18          4859763987   \n",
       "2               0 2017-04-12 17:57:18          3537421936   \n",
       "3               0 2017-04-12 17:57:18          3056458174   \n",
       "4               0 2017-04-12 17:57:18  849320016315023362   \n",
       "5               0 2017-04-12 17:57:18            43871279   \n",
       "6               0 2017-04-12 17:57:18            30308791   \n",
       "7               0 2017-04-12 17:57:18            46049431   \n",
       "8               0 2017-04-12 17:57:18          3431548829   \n",
       "9               0 2017-04-12 17:57:18           356713597   \n",
       "\n",
       "  from_user_created_at  from_user_favorites  from_user_followers  \\\n",
       "0  2011-05-05 20:04:11                  180                  570   \n",
       "1  2016-01-29 10:24:41                  129                   54   \n",
       "2  2015-09-03 20:10:35                 1724                  330   \n",
       "3  2015-02-23 16:59:19                50357                 6117   \n",
       "4  2017-04-04 17:57:26                 1067                  179   \n",
       "5  2009-06-01 11:50:18                71484                 2588   \n",
       "6  2009-04-10 20:46:41                13742                  473   \n",
       "7  2009-06-10 05:56:50                  283                 6197   \n",
       "8  2015-08-19 14:21:23                  592                   25   \n",
       "9  2011-08-17 07:44:59                 6372                  362   \n",
       "\n",
       "   from_user_following   from_user_fullname    from_user_id_str  \\\n",
       "0                  711               âï¸           293690109   \n",
       "1                  331  Reinardo jose silva          4859763987   \n",
       "2                  268                Karen          3537421936   \n",
       "3                 5763    PROMO GANG C.E.O.          3056458174   \n",
       "4                  454           Bob Abooey  849320016315023362   \n",
       "5                 2298         absentminded            43871279   \n",
       "6                  596        Shaker Pepper            30308791   \n",
       "7                 1693        Plushbeds.com            46049431   \n",
       "8                  106             RRussell          3431548829   \n",
       "9                  714                 Leah           356713597   \n",
       "\n",
       "  from_user_name         ...         job_id  location_geo location_geo_0  \\\n",
       "0      _Butter21         ...            210          None           None   \n",
       "1    JoseVerde28         ...            223          None           None   \n",
       "2  karen_marin02         ...            236          None           None   \n",
       "3        ceep757         ...            284          None           None   \n",
       "4     BobAbooey8         ...            275          None           None   \n",
       "5          mlccm         ...            290          None           None   \n",
       "6    shakepepper         ...            269          None           None   \n",
       "7      plushbeds         ...            284          None           None   \n",
       "8  RRussell74351         ...            255          None           None   \n",
       "9    brLeaHkaway         ...            275          None           None   \n",
       "\n",
       "   location_geo_1                                             source  \\\n",
       "0            None  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1            None  <a href=\"http://blackberry.com/twitter\" rel=\"n...   \n",
       "2            None  <a href=\"http://twitter.com/download/android\" ...   \n",
       "3            None  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "4            None  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "5            None  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "6            None  <a href=\"http://twitter.com/#!/download/ipad\" ...   \n",
       "7            None  <a href=\"http://www.audiense.com\" rel=\"nofollo...   \n",
       "8            None  <a href=\"http://www.twitter.com\" rel=\"nofollow...   \n",
       "9            None  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text   to_user to_user_id_str  \\\n",
       "0  RT @BleacherReport: MLB commish Rob Manfred wa...      None           None   \n",
       "1  RT @WarOfParlay: Ayer Lamentablemente fue un d...      None           None   \n",
       "2  Si no te importa lo que piense la gente, ya di...      None           None   \n",
       "3  RT @TUOWLS_WBB: Our Big 5 award winners... hig...      None           None   \n",
       "4  Watch Shia LaBeouf Text People From A Remote C...      None           None   \n",
       "5  RT @nattylumpo88: Ok. Alright. We get it. You ...      None           None   \n",
       "6  RT @cdotharrison: I saw Charlie Murphy at the ...      None           None   \n",
       "7  @HBQ_1 We've got a question for you: about how...  17570566       17570566   \n",
       "8  RT @saladinahmed: it's not 'sharia' if you're ...      None           None   \n",
       "9  RT @celtics: Get ready for the playoffs with t...      None           None   \n",
       "\n",
       "  to_user_name        tweet_id_str  \n",
       "0         None  852219087375781889  \n",
       "1         None  852219087405150209  \n",
       "2         None  852219087442915330  \n",
       "3         None  852219087530991624  \n",
       "4         None  852219087631650816  \n",
       "5         None  852219087845511173  \n",
       "6         None  852219087954493440  \n",
       "7        HBQ_1  852219087967145984  \n",
       "8         None  852219088059412482  \n",
       "9         None  852219088113999882  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tweet_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Back to linguistic diversity...** \n",
    "\n",
    "So we know that one of the component of linguistic diversity includes the number of unique languages.  We can find the unique langauges through a simple query of the database. Below we find the unique languages from 10,000 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #E6E6FA\">**A Note about Limits**: We limit the data returned to 10,000 rows because there are approximately 300 million tweets in the total datasset. If everyone queried the whole table without limits at the same time, we would need a much larger server!  If you are curious about the results for all the tweets, drop us a note and we will run your analysis when the server load is low (i.e., while you sleep!).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statement = \"\"\"SELECT DISTINCT iso_language \n",
    "FROM (SELECT iso_language FROM twitter.tweet LIMIT 10000) AS langs\"\"\"\n",
    "\n",
    "try:\n",
    "    connect_str = \"dbname='twitter' user='dsa_ro_user' host='dbase.dsa.missouri.edu'password='readonly'\"\n",
    "    # use our connection values to establish a connection\n",
    "    conn = psycopg2.connect(connect_str)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(statement)\n",
    "\n",
    "    langs = cursor.fetchall()\n",
    "except Exception as e:\n",
    "    print(\"Uh oh, can't connect. Invalid dbname, user or password?\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now the languages are in a variable called \"lang\". To view that variable, we simply type it in an output window like below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pt',),\n",
       " ('cy',),\n",
       " ('ru',),\n",
       " ('de',),\n",
       " ('fr',),\n",
       " ('es',),\n",
       " ('nl',),\n",
       " ('ro',),\n",
       " ('el',),\n",
       " ('is',),\n",
       " ('eu',),\n",
       " ('tr',),\n",
       " ('pl',),\n",
       " ('ja',),\n",
       " ('th',),\n",
       " ('da',),\n",
       " ('ar',),\n",
       " ('lv',),\n",
       " ('fi',),\n",
       " ('und',),\n",
       " ('lt',),\n",
       " ('en',),\n",
       " ('in',),\n",
       " ('tl',),\n",
       " ('ko',),\n",
       " ('et',),\n",
       " ('no',),\n",
       " ('sv',),\n",
       " ('it',),\n",
       " ('iw',),\n",
       " ('ht',)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background-color: #FFFF00\">YOUR TURN</span>\n",
    "\n",
    "How many unique languages are there from 10,000 rows. Feel free to use SQL or Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(40,)]\n"
     ]
    }
   ],
   "source": [
    "# put your code here\n",
    "# ------------------\n",
    "\n",
    "statement = \"\"\"SELECT COUNT(*) FROM (SELECT DISTINCT iso_language \n",
    "FROM (SELECT iso_language FROM twitter.tweet LIMIT 10000) AS langs) AS lang_count\"\"\"\n",
    "\n",
    "try:\n",
    "    connect_str = \"dbname='twitter' user='dsa_ro_user' host='dbase.dsa.missouri.edu'password='readonly'\"\n",
    "    # use our connection values to establish a connection\n",
    "    conn = psycopg2.connect(connect_str)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(statement)\n",
    "    num_langs = cursor.fetchall()\n",
    "except Exception as e:\n",
    "    print(\"Uh oh, can't connect. Invalid dbname, user or password?\")\n",
    "    print(e)\n",
    "    \n",
    "print(num_langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other component of diversity is the number of speakers per language (at least for our measure). Again, this can be done in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('es', 388), ('th', 12), ('cs', 1), ('tl', 55), ('lt', 4), ('ar', 18), ('sv', 5), ('in', 44), ('nl', 10), ('is', 2), ('fi', 4), ('no', 3), ('ko', 34), ('cy', 5), ('pl', 3), ('da', 4), ('ro', 3), ('eu', 1), ('ht', 16), ('et', 13), ('und', 621), ('pt', 57), ('ru', 4), ('hi', 1), ('fr', 17), ('ja', 79), ('en', 8557), ('de', 17), ('ur', 2), ('tr', 8), ('it', 11), ('zh', 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# use COUNT with a GROUP BY to count the number of speakers per language\n",
    "statement = \"\"\"SELECT DISTINCT iso_language, COUNT(*) \n",
    "FROM (SELECT iso_language FROM twitter.tweet LIMIT 10000) AS langs GROUP BY iso_language;\"\"\"\n",
    "\n",
    "try:\n",
    "    connect_str = \"dbname='twitter' user='dsa_ro_user' host='dbase.dsa.missouri.edu'password='readonly'\"\n",
    "    # use our connection values to establish a connection\n",
    "    conn = psycopg2.connect(connect_str)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(statement)\n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "    num_langs = cursor.fetchall()\n",
    "except Exception as e:\n",
    "    print(\"Uh oh, can't connect. Invalid dbname, user or password?\")\n",
    "    print(e)\n",
    "    \n",
    "print(num_langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background-color: #FFFF00\">YOUR TURN</span>\n",
    "\n",
    "Put the above counts in a data frame object where one column is the language and the other is the number of speakers (which are really represented as tweets by language) for that language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>iso_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>388</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>lt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>sv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34</td>\n",
       "      <td>ko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>cy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>ro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16</td>\n",
       "      <td>ht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13</td>\n",
       "      <td>et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>621</td>\n",
       "      <td>und</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>57</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>79</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8557</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>17</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>zh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count iso_language\n",
       "0     388           es\n",
       "1      12           th\n",
       "2       1           cs\n",
       "3      55           tl\n",
       "4       4           lt\n",
       "5      18           ar\n",
       "6       5           sv\n",
       "7      44           in\n",
       "8      10           nl\n",
       "9       2           is\n",
       "10      4           fi\n",
       "11      3           no\n",
       "12     34           ko\n",
       "13      5           cy\n",
       "14      3           pl\n",
       "15      4           da\n",
       "16      3           ro\n",
       "17      1           eu\n",
       "18     16           ht\n",
       "19     13           et\n",
       "20    621          und\n",
       "21     57           pt\n",
       "22      4           ru\n",
       "23      1           hi\n",
       "24     17           fr\n",
       "25     79           ja\n",
       "26   8557           en\n",
       "27     17           de\n",
       "28      2           ur\n",
       "29      8           tr\n",
       "30     11           it\n",
       "31      1           zh"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put your code here\n",
    "# ------------------\n",
    "\n",
    "lang_dict = {}\n",
    "for i in list(range(len(column_names))):\n",
    "     lang_dict['{}'.format(column_names[i])] = [x[i] for x in num_langs]\n",
    "        \n",
    "pd.DataFrame(lang_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "These were the basics. There is still a long way to go before we are ready for analysis, but this is a good place to start as we will use these statements as building blocks for the rest of the *Twitter* notebooks. In the next notebook, we will cover further data manipulation and preparation in order to get it in a state that is ready for analysis. This will include the removal of some rows and more aggregations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
